{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f05201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from kerastuner import RandomSearch\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df38a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Skipping file /Users/nasifsafwan/Downloads/ML/BrainTumorResearch/tumordata/Training/glioma_tumor/.DS_Store as it is not a valid image.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "train_img = []\n",
    "train_labels = []\n",
    "\n",
    "test_img = []\n",
    "test_labels = []\n",
    "\n",
    "path_train = '/Users/nasifsafwan/Downloads/ML/BrainTumorResearch/tumordata/Training/'\n",
    "path_test = '/Users/nasifsafwan/Downloads/ML/BrainTumorResearch/tumordata/Testing/'\n",
    "img_size = 300\n",
    "\n",
    "# Function to process images in a given directory\n",
    "def process_images(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for category in os.listdir(path):\n",
    "        category_path = os.path.join(path, category)\n",
    "        if os.path.isdir(category_path):  # Ensure it's a directory\n",
    "            for img_name in os.listdir(category_path):\n",
    "                img_path = os.path.join(category_path, img_name)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    resized_img = cv2.resize(img, (img_size, img_size))\n",
    "                    images.append(resized_img)\n",
    "                    labels.append(category)\n",
    "                else:\n",
    "                    print(f\"Warning: Skipping file {img_path} as it is not a valid image.\")\n",
    "    return images, labels\n",
    "\n",
    "# Process training and testing data\n",
    "train_img, train_labels = process_images(path_train)\n",
    "test_img, test_labels = process_images(path_test)\n",
    "\n",
    "train_img = np.array(train_img)\n",
    "test_img = np.array(test_img)\n",
    "\n",
    "# Encode labels\n",
    "train_labels_encoded = [0 if category == 'no_tumor' else (1 if category == 'glioma_tumor' else (2 if category == 'meningioma_tumor' else 3)) for category in train_labels]\n",
    "test_labels_encoded = [0 if category == 'no_tumor' else (1 if category == 'glioma_tumor' else (2 if category == 'meningioma_tumor' else 3)) for category in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4996e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = tf.cast(train_img, tf.float32)\n",
    "test_img = tf.cast(test_img, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f41bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "train_labels_encoded = np.array(pd.get_dummies(train_labels))\n",
    "test_labels_encoded = np.array(pd.get_dummies(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f41e1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.keras.backend.flatten(tf.cast(y_true, tf.float32))\n",
    "    y_pred_f = tf.keras.backend.flatten(tf.cast(y_pred, tf.float32))\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "# Define Hausdorff distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    if isinstance(y_true, tf.Tensor):\n",
    "        y_true = y_true.numpy()\n",
    "    if isinstance(y_pred, tf.Tensor):\n",
    "        y_pred = y_pred.numpy()\n",
    "    \n",
    "    # Convert to binary masks\n",
    "    y_true = (y_true > 0.5).astype(int)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    # Check if masks are 2D\n",
    "    if y_true.ndim == 1:\n",
    "        y_true = np.expand_dims(y_true, axis=0)\n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred = np.expand_dims(y_pred, axis=0)\n",
    "    \n",
    "    # Flatten masks to 1D\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    \n",
    "    # Compute Hausdorff distance\n",
    "    hd = directed_hausdorff(y_true_flat, y_pred_flat)[0]\n",
    "    return hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e5611b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "img_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "img_datagen.fit(train_img)\n",
    "img_datagen.fit(test_img)\n",
    "\n",
    "train_generator = img_datagen.flow(train_img, train_labels_encoded, batch_size=32)\n",
    "validation_generator = img_datagen.flow(test_img, test_labels_encoded, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0fceb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(kernel_size=(5, 5), filters=32, activation='relu', padding='same', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=32, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=32, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=32, activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(4, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', dice_coefficient, tf.keras.metrics.MeanAbsoluteError(), tf.keras.metrics.MeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dde89020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 874ms/step - accuracy: 0.3419 - dice_coefficient: 0.3592 - loss: 7.0907 - mean_absolute_error: 0.4879 - mean_squared_error: 0.3173 - val_accuracy: 0.2552 - val_dice_coefficient: 0.3347 - val_loss: 1.6595 - val_mean_absolute_error: 0.5131 - val_mean_squared_error: 0.2896\n",
      "Epoch 2/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 780us/step - accuracy: 0.4062 - dice_coefficient: 0.2093 - loss: 1.3202 - mean_absolute_error: 0.4740 - mean_squared_error: 0.2800 - val_accuracy: 0.3000 - val_dice_coefficient: 0.1904 - val_loss: 1.4535 - val_mean_absolute_error: 0.4865 - val_mean_squared_error: 0.2696\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 01:42:50.274024: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-29 01:42:50.328729: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 859ms/step - accuracy: 0.4066 - dice_coefficient: 0.3925 - loss: 1.2391 - mean_absolute_error: 0.4839 - mean_squared_error: 0.2642 - val_accuracy: 0.3281 - val_dice_coefficient: 0.3431 - val_loss: 1.6343 - val_mean_absolute_error: 0.5310 - val_mean_squared_error: 0.3113\n",
      "Epoch 4/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 665us/step - accuracy: 0.4062 - dice_coefficient: 0.1983 - loss: 1.2679 - mean_absolute_error: 0.4971 - mean_squared_error: 0.2779 - val_accuracy: 0.1000 - val_dice_coefficient: 0.1544 - val_loss: 1.9457 - val_mean_absolute_error: 0.5552 - val_mean_squared_error: 0.3434\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 01:44:10.300010: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-29 01:44:10.350880: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 856ms/step - accuracy: 0.4384 - dice_coefficient: 0.4069 - loss: 1.1980 - mean_absolute_error: 0.4843 - mean_squared_error: 0.2763 - val_accuracy: 0.3281 - val_dice_coefficient: 0.3540 - val_loss: 1.7900 - val_mean_absolute_error: 0.5305 - val_mean_squared_error: 0.3298\n",
      "Epoch 6/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669us/step - accuracy: 0.4375 - dice_coefficient: 0.2042 - loss: 1.2685 - mean_absolute_error: 0.4905 - mean_squared_error: 0.2894 - val_accuracy: 0.4000 - val_dice_coefficient: 0.2069 - val_loss: 1.2941 - val_mean_absolute_error: 0.4943 - val_mean_squared_error: 0.3046\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 01:45:30.001525: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-29 01:45:30.052668: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 859ms/step - accuracy: 0.4953 - dice_coefficient: 0.4214 - loss: 1.1317 - mean_absolute_error: 0.4685 - mean_squared_error: 0.2700 - val_accuracy: 0.2500 - val_dice_coefficient: 0.3647 - val_loss: 1.8045 - val_mean_absolute_error: 0.5338 - val_mean_squared_error: 0.3465\n",
      "Epoch 8/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679us/step - accuracy: 0.4688 - dice_coefficient: 0.2260 - loss: 1.1976 - mean_absolute_error: 0.4575 - mean_squared_error: 0.2947 - val_accuracy: 0.2000 - val_dice_coefficient: 0.2085 - val_loss: 1.4498 - val_mean_absolute_error: 0.5055 - val_mean_squared_error: 0.3415\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 01:46:49.908611: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-29 01:46:49.960412: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 861ms/step - accuracy: 0.5123 - dice_coefficient: 0.4440 - loss: 1.0695 - mean_absolute_error: 0.4563 - mean_squared_error: 0.2764 - val_accuracy: 0.3307 - val_dice_coefficient: 0.3719 - val_loss: 1.9957 - val_mean_absolute_error: 0.5168 - val_mean_squared_error: 0.3414\n",
      "Epoch 10/10\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663us/step - accuracy: 0.5625 - dice_coefficient: 0.2538 - loss: 0.7260 - mean_absolute_error: 0.4070 - mean_squared_error: 0.2546 - val_accuracy: 0.2000 - val_dice_coefficient: 0.1307 - val_loss: 3.6418 - val_mean_absolute_error: 0.6172 - val_mean_squared_error: 0.4541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 01:48:10.029493: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-29 01:48:10.080303: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_generator, \n",
    "                    steps_per_epoch=len(train_img) // 32, \n",
    "                    epochs=10, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=len(test_img) // 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86dade12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 820ms/step - accuracy: 0.6259 - dice_coefficient: 0.4952 - loss: 0.8584 - mean_absolute_error: 0.4271 - mean_squared_error: 0.2875 - val_accuracy: 0.9477 - val_dice_coefficient: 0.5241 - val_loss: 0.3659 - val_mean_absolute_error: 0.4225 - val_mean_squared_error: 0.2678\n",
      "Epoch 2/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 834ms/step - accuracy: 0.7453 - dice_coefficient: 0.5344 - loss: 0.5857 - mean_absolute_error: 0.4061 - mean_squared_error: 0.3023 - val_accuracy: 0.9164 - val_dice_coefficient: 0.5811 - val_loss: 0.3038 - val_mean_absolute_error: 0.3414 - val_mean_squared_error: 0.2219\n",
      "Epoch 3/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 832ms/step - accuracy: 0.8179 - dice_coefficient: 0.5526 - loss: 0.4766 - mean_absolute_error: 0.3851 - mean_squared_error: 0.2987 - val_accuracy: 0.9826 - val_dice_coefficient: 0.5742 - val_loss: 0.1647 - val_mean_absolute_error: 0.3613 - val_mean_squared_error: 0.2352\n",
      "Epoch 4/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 852ms/step - accuracy: 0.8202 - dice_coefficient: 0.5490 - loss: 0.4335 - mean_absolute_error: 0.3949 - mean_squared_error: 0.3119 - val_accuracy: 0.9338 - val_dice_coefficient: 0.5951 - val_loss: 0.2391 - val_mean_absolute_error: 0.3316 - val_mean_squared_error: 0.2418\n",
      "Epoch 5/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 882ms/step - accuracy: 0.8680 - dice_coefficient: 0.5721 - loss: 0.3148 - mean_absolute_error: 0.3661 - mean_squared_error: 0.2976 - val_accuracy: 0.8850 - val_dice_coefficient: 0.5743 - val_loss: 0.3318 - val_mean_absolute_error: 0.3549 - val_mean_squared_error: 0.2470\n",
      "Epoch 6/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 845ms/step - accuracy: 0.8827 - dice_coefficient: 0.5759 - loss: 0.2848 - mean_absolute_error: 0.3600 - mean_squared_error: 0.2896 - val_accuracy: 0.9756 - val_dice_coefficient: 0.6209 - val_loss: 0.0641 - val_mean_absolute_error: 0.3033 - val_mean_squared_error: 0.2292\n",
      "Epoch 7/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 854ms/step - accuracy: 0.9116 - dice_coefficient: 0.5785 - loss: 0.2010 - mean_absolute_error: 0.3595 - mean_squared_error: 0.3010 - val_accuracy: 0.9756 - val_dice_coefficient: 0.6409 - val_loss: 0.0801 - val_mean_absolute_error: 0.2779 - val_mean_squared_error: 0.1970\n",
      "Epoch 8/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 834ms/step - accuracy: 0.9150 - dice_coefficient: 0.5963 - loss: 0.1882 - mean_absolute_error: 0.3351 - mean_squared_error: 0.2790 - val_accuracy: 0.9721 - val_dice_coefficient: 0.5918 - val_loss: 0.1132 - val_mean_absolute_error: 0.3435 - val_mean_squared_error: 0.2766\n",
      "Epoch 9/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 819ms/step - accuracy: 0.9193 - dice_coefficient: 0.5761 - loss: 0.1776 - mean_absolute_error: 0.3656 - mean_squared_error: 0.3116 - val_accuracy: 0.9721 - val_dice_coefficient: 0.5857 - val_loss: 0.0885 - val_mean_absolute_error: 0.3534 - val_mean_squared_error: 0.2899\n",
      "Epoch 10/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 816ms/step - accuracy: 0.9269 - dice_coefficient: 0.5703 - loss: 0.1305 - mean_absolute_error: 0.3750 - mean_squared_error: 0.3205 - val_accuracy: 0.9373 - val_dice_coefficient: 0.6263 - val_loss: 0.1912 - val_mean_absolute_error: 0.2961 - val_mean_squared_error: 0.2334\n",
      "Epoch 11/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 862ms/step - accuracy: 0.9351 - dice_coefficient: 0.5814 - loss: 0.1320 - mean_absolute_error: 0.3588 - mean_squared_error: 0.3108 - val_accuracy: 0.9826 - val_dice_coefficient: 0.6663 - val_loss: 0.0624 - val_mean_absolute_error: 0.2500 - val_mean_squared_error: 0.1962\n",
      "Epoch 12/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 846ms/step - accuracy: 0.9181 - dice_coefficient: 0.5947 - loss: 0.1616 - mean_absolute_error: 0.3391 - mean_squared_error: 0.2925 - val_accuracy: 0.9582 - val_dice_coefficient: 0.6308 - val_loss: 0.1552 - val_mean_absolute_error: 0.2922 - val_mean_squared_error: 0.2388\n",
      "Epoch 13/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 889ms/step - accuracy: 0.9110 - dice_coefficient: 0.5857 - loss: 0.1398 - mean_absolute_error: 0.3519 - mean_squared_error: 0.3041 - val_accuracy: 0.9895 - val_dice_coefficient: 0.6173 - val_loss: 0.0218 - val_mean_absolute_error: 0.3100 - val_mean_squared_error: 0.2686\n",
      "Epoch 14/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 885ms/step - accuracy: 0.8982 - dice_coefficient: 0.5801 - loss: 0.1001 - mean_absolute_error: 0.3612 - mean_squared_error: 0.3210 - val_accuracy: 0.9652 - val_dice_coefficient: 0.6376 - val_loss: 0.1169 - val_mean_absolute_error: 0.2833 - val_mean_squared_error: 0.2344\n",
      "Epoch 15/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 820ms/step - accuracy: 0.9247 - dice_coefficient: 0.5956 - loss: 0.0877 - mean_absolute_error: 0.3391 - mean_squared_error: 0.2961 - val_accuracy: 0.9861 - val_dice_coefficient: 0.6563 - val_loss: 0.0558 - val_mean_absolute_error: 0.2615 - val_mean_squared_error: 0.2034\n",
      "Epoch 16/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 818ms/step - accuracy: 0.9047 - dice_coefficient: 0.5991 - loss: 0.1108 - mean_absolute_error: 0.3337 - mean_squared_error: 0.2952 - val_accuracy: 0.9756 - val_dice_coefficient: 0.6596 - val_loss: 0.0587 - val_mean_absolute_error: 0.2568 - val_mean_squared_error: 0.1914\n",
      "Epoch 17/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 827ms/step - accuracy: 0.9359 - dice_coefficient: 0.5988 - loss: 0.0960 - mean_absolute_error: 0.3341 - mean_squared_error: 0.2882 - val_accuracy: 0.9756 - val_dice_coefficient: 0.6107 - val_loss: 0.0473 - val_mean_absolute_error: 0.3187 - val_mean_squared_error: 0.2476\n",
      "Epoch 18/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 818ms/step - accuracy: 0.9235 - dice_coefficient: 0.5888 - loss: 0.0920 - mean_absolute_error: 0.3478 - mean_squared_error: 0.3058 - val_accuracy: 0.9686 - val_dice_coefficient: 0.6282 - val_loss: 0.1067 - val_mean_absolute_error: 0.2956 - val_mean_squared_error: 0.2408\n",
      "Epoch 19/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 835ms/step - accuracy: 0.9337 - dice_coefficient: 0.6138 - loss: 0.0730 - mean_absolute_error: 0.3142 - mean_squared_error: 0.2745 - val_accuracy: 0.9617 - val_dice_coefficient: 0.6065 - val_loss: 0.1064 - val_mean_absolute_error: 0.3230 - val_mean_squared_error: 0.2660\n",
      "Epoch 20/20\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 820ms/step - accuracy: 0.9083 - dice_coefficient: 0.6113 - loss: 0.0716 - mean_absolute_error: 0.3174 - mean_squared_error: 0.2810 - val_accuracy: 0.9721 - val_dice_coefficient: 0.6047 - val_loss: 0.0780 - val_mean_absolute_error: 0.3265 - val_mean_squared_error: 0.2593\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tf.cast(train_img,tf.float32),\n",
    "                    np.array(pd.get_dummies(train_labels)),\n",
    "                    validation_split=0.1,epochs=20,\n",
    "                   verbose=1,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8af2250b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m             total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_hausdorff_distance \u001b[38;5;241m/\u001b[39m total_samples\n\u001b[0;32m---> 21\u001b[0m hausdorff_avg \u001b[38;5;241m=\u001b[39m evaluate_model(model, validation_generator)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Hausdorff Distance:\u001b[39m\u001b[38;5;124m\"\u001b[39m, hausdorff_avg)\n",
      "Cell \u001b[0;32mIn[40], line 15\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_generator)\u001b[0m\n\u001b[1;32m     12\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (y_pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Compute Hausdorff distance\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m hd \u001b[38;5;241m=\u001b[39m hausdorff_distance(y_true, y_pred)\n\u001b[1;32m     16\u001b[0m total_hausdorff_distance \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m hd\n\u001b[1;32m     17\u001b[0m total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[37], line 29\u001b[0m, in \u001b[0;36mhausdorff_distance\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     26\u001b[0m y_pred_flat \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Compute Hausdorff distance\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m hd \u001b[38;5;241m=\u001b[39m directed_hausdorff(y_true_flat, y_pred_flat)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hd\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/spatial/distance.py:422\u001b[0m, in \u001b[0;36mdirected_hausdorff\u001b[0;34m(u, v, seed)\u001b[0m\n\u001b[1;32m    420\u001b[0m u \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(u, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    421\u001b[0m v \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(v, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m u\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m v\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu and v need to have the same \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    424\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber of columns\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    425\u001b[0m result \u001b[38;5;241m=\u001b[39m _hausdorff\u001b[38;5;241m.\u001b[39mdirected_hausdorff(u, v, seed)\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_generator):\n",
    "    total_hausdorff_distance = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for i in range(len(test_generator)):\n",
    "        x_batch, y_batch = next(test_generator)\n",
    "        predictions = model.predict(x_batch)\n",
    "        \n",
    "        for y_true, y_pred in zip(y_batch, predictions):\n",
    "            # Convert to binary masks\n",
    "            y_true = (y_true > 0.5).astype(bool)\n",
    "            y_pred = (y_pred > 0.5).astype(bool)\n",
    "            \n",
    "            # Compute Hausdorff distance\n",
    "            hd = hausdorff_distance(y_true, y_pred)\n",
    "            total_hausdorff_distance += hd\n",
    "            total_samples += 1\n",
    "    \n",
    "    return total_hausdorff_distance / total_samples\n",
    "\n",
    "hausdorff_avg = evaluate_model(model, validation_generator)\n",
    "print(\"Average Hausdorff Distance:\", hausdorff_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274399f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
