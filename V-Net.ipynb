{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da3e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from scipy.spatial.distance import directed_hausdorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae6cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = []\n",
    "train_labels = []\n",
    "\n",
    "test_img = []\n",
    "test_labels = []\n",
    "\n",
    "path_train = '/Users/nasifsafwan/Downloads/ML/BrainTumorResearch/tumordata/Training/'\n",
    "path_test = '/Users/nasifsafwan/Downloads/ML/BrainTumorResearch/tumordata/Testing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6967d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for category in os.listdir(path):\n",
    "        category_path = os.path.join(path, category)\n",
    "        if os.path.isdir(category_path):  # Ensure it's a directory\n",
    "            for img_name in os.listdir(category_path):\n",
    "                img_path = os.path.join(category_path, img_name)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    resized_img = cv2.resize(img, (img_size, img_size))\n",
    "                    if len(resized_img.shape) == 2:  # Convert grayscale to RGB\n",
    "                        resized_img = cv2.cvtColor(resized_img, cv2.COLOR_GRAY2RGB)\n",
    "                    images.append(resized_img)\n",
    "                    labels.append(category)\n",
    "                else:\n",
    "                    print(f\"Warning: Skipping file {img_path} as it is not a valid image.\")\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acdd7a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),   # Convert from NumPy array to PIL Image\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),     # Convert from PIL Image to PyTorch Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e63abc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.batch_norm = nn.BatchNorm3d(out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batch_norm(self.conv1(x)))\n",
    "        x = F.relu(self.batch_norm(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.conv_block = ConvBlock(in_channels, out_channels)\n",
    "        self.pool = nn.Conv3d(out_channels, out_channels, kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        pooled = self.pool(x)\n",
    "        return x, pooled\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.conv_block = ConvBlock(in_channels, out_channels)\n",
    "        self.up = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x, bridge):\n",
    "        upsampled = self.up(x)\n",
    "        out = torch.cat([upsampled, bridge], dim=1)\n",
    "        out = self.conv_block(out)\n",
    "        return out\n",
    "\n",
    "class VNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VNet, self).__init__()\n",
    "        self.down1 = DownBlock(1, 16)\n",
    "        self.down2 = DownBlock(16, 32)\n",
    "        self.down3 = DownBlock(32, 64)\n",
    "        self.down4 = DownBlock(64, 128)\n",
    "        \n",
    "        self.bottleneck = ConvBlock(128, 256)\n",
    "        \n",
    "        self.up1 = UpBlock(256, 128)\n",
    "        self.up2 = UpBlock(128, 64)\n",
    "        self.up3 = UpBlock(64, 32)\n",
    "        self.up4 = UpBlock(32, 16)\n",
    "        \n",
    "        self.final_conv = nn.Conv3d(16, num_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bridge1, down1 = self.down1(x)\n",
    "        bridge2, down2 = self.down2(down1)\n",
    "        bridge3, down3 = self.down3(down2)\n",
    "        bridge4, down4 = self.down4(down3)\n",
    "        \n",
    "        bottleneck = self.bottleneck(down4)\n",
    "        \n",
    "        up1 = self.up1(bottleneck, bridge4)\n",
    "        up2 = self.up2(up1, bridge3)\n",
    "        up3 = self.up3(up2, bridge2)\n",
    "        up4 = self.up4(up3, bridge1)\n",
    "        \n",
    "        out = self.final_conv(up4)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd163a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'no_tumor': 0, 'glioma_tumor': 1, 'meningioma_tumor': 2, 'pituitary_tumor': 3}\n",
    "train_labels_encoded = [label_map[label] for label in train_labels]\n",
    "test_labels_encoded = [label_map[label] for label in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefdedd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BrainTumorDataset(train_img, train_labels_encoded, transform=transform)\n",
    "test_dataset = BrainTumorDataset(test_img, test_labels_encoded, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce52453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_dataset = ImageFolder(root=path_train, transform=transform)\n",
    "test_dataset = ImageFolder(root=path_test, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = VNet(in_channels=3, out_channels=4)\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Define Dice Coefficient\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true_f = y_true.contiguous().view(-1)\n",
    "    y_pred_f = y_pred.contiguous().view(-1)\n",
    "    intersection = (y_true_f * y_pred_f).sum()\n",
    "    return (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
    "\n",
    "# Define Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    return max(directed_hausdorff(y_true, y_pred)[0], directed_hausdorff(y_pred, y_true)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b31438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images = images.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        labels = labels.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e8be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f0d66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e2e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01737072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de134125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ad1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8cfe09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b64962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "# Dataset Class\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "# Dataset Class\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Ensure image has 3 channels\n",
    "        if len(image.shape) == 2:  # Grayscale image\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "        elif image.shape[2] == 4:  # Image with alpha channel\n",
    "            image = image[:, :, :3]  # Remove alpha channel\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# V-Net Model\n",
    "class VNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=4):\n",
    "        super(VNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(32, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Image Processing Function\n",
    "def process_images(path, img_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for category in os.listdir(path):\n",
    "        category_path = os.path.join(path, category)\n",
    "        if os.path.isdir(category_path):  # Ensure it's a directory\n",
    "            for img_name in os.listdir(category_path):\n",
    "                img_path = os.path.join(category_path, img_name)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    resized_img = cv2.resize(img, (img_size, img_size))\n",
    "                    if len(resized_img.shape) == 2:  # Convert grayscale to RGB\n",
    "                        resized_img = cv2.cvtColor(resized_img, cv2.COLOR_GRAY2RGB)\n",
    "                    elif resized_img.shape[2] == 4:  # Handle images with an alpha channel\n",
    "                        resized_img = resized_img[:, :, :3]\n",
    "                    images.append(resized_img)\n",
    "                    labels.append(category)\n",
    "                else:\n",
    "                    print(f\"Warning: Skipping file {img_path} as it is not a valid image.\")\n",
    "    return images, labels\n",
    "\n",
    "# Define paths\n",
    "path_train = '/Users/nasifsafwan/Downloads/ML/BrainTumorResearch/tumordata/Training/'\n",
    "path_test = '/Users/nasifsafwan/Downloads/ML/BrainTumorResearch/tumordata/Testing/'\n",
    "img_size = 300\n",
    "\n",
    "# Process training and testing data\n",
    "train_img, train_labels = process_images(path_train, img_size)\n",
    "test_img, test_labels = process_images(path_test, img_size)\n",
    "\n",
    "train_img = np.array(train_img)\n",
    "test_img = np.array(test_img)\n",
    "\n",
    "# Encode labels\n",
    "label_map = {'no_tumor': 0, 'glioma_tumor': 1, 'meningioma_tumor': 2, 'pituitary_tumor': 3}\n",
    "train_labels_encoded = [label_map[label] for label in train_labels]\n",
    "test_labels_encoded = [label_map[label] for label in test_labels]\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "train_dataset = BrainTumorDataset(train_img, train_labels_encoded, transform=transform)\n",
    "test_dataset = BrainTumorDataset(test_img, test_labels_encoded, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Verify the shape of a batch\n",
    "for images, labels in train_loader:\n",
    "    print(f'Batch shape: {images.shape}')\n",
    "    break\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = VNet(in_channels=3, out_channels=4)\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Define Dice Coefficient\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    smooth = 1e-6\n",
    "    y_true_f = y_true.contiguous().view(-1)\n",
    "    y_pred_f = y_pred.contiguous().view(-1)\n",
    "    intersection = (y_true_f * y_pred_f).sum()\n",
    "    return (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
    "\n",
    "# Define Hausdorff Distance\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    return max(directed_hausdorff(y_true, y_pred)[0], directed_hausdorff(y_pred, y_true)[0])\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images = images.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        labels = labels.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c16721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06788de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6967aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affcf3c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_images.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 92\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(image, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), torch\u001b[38;5;241m.\u001b[39mtensor(mask, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Load your data\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Note: Replace these with the actual paths to your training and testing datasets\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m train_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_images.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     93\u001b[0m train_masks \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_masks.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m test_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_images.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28mopen\u001b[39m(os_fspath(file), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_images.npy'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.batch_norm = nn.BatchNorm3d(out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batch_norm(self.conv1(x)))\n",
    "        x = F.relu(self.batch_norm(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.conv_block = ConvBlock(in_channels, out_channels)\n",
    "        self.pool = nn.Conv3d(out_channels, out_channels, kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        pooled = self.pool(x)\n",
    "        return x, pooled\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.conv_block = ConvBlock(in_channels, out_channels)\n",
    "        self.up = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x, bridge):\n",
    "        upsampled = self.up(x)\n",
    "        out = torch.cat([upsampled, bridge], dim=1)\n",
    "        out = self.conv_block(out)\n",
    "        return out\n",
    "\n",
    "class VNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VNet, self).__init__()\n",
    "        self.down1 = DownBlock(1, 16)\n",
    "        self.down2 = DownBlock(16, 32)\n",
    "        self.down3 = DownBlock(32, 64)\n",
    "        self.down4 = DownBlock(64, 128)\n",
    "        \n",
    "        self.bottleneck = ConvBlock(128, 256)\n",
    "        \n",
    "        self.up1 = UpBlock(256, 128)\n",
    "        self.up2 = UpBlock(128, 64)\n",
    "        self.up3 = UpBlock(64, 32)\n",
    "        self.up4 = UpBlock(32, 16)\n",
    "        \n",
    "        self.final_conv = nn.Conv3d(16, num_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bridge1, down1 = self.down1(x)\n",
    "        bridge2, down2 = self.down2(down1)\n",
    "        bridge3, down3 = self.down3(down2)\n",
    "        bridge4, down4 = self.down4(down3)\n",
    "        \n",
    "        bottleneck = self.bottleneck(down4)\n",
    "        \n",
    "        up1 = self.up1(bottleneck, bridge4)\n",
    "        up2 = self.up2(up1, bridge3)\n",
    "        up3 = self.up3(up2, bridge2)\n",
    "        up4 = self.up4(up3, bridge1)\n",
    "        \n",
    "        out = self.final_conv(up4)\n",
    "        return out\n",
    "\n",
    "# Create a sample dataset\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, images, masks):\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(mask, dtype=torch.long)\n",
    "\n",
    "# Load your data\n",
    "# Note: Replace these with the actual paths to your training and testing datasets\n",
    "train_images = np.load('train_images.npy')\n",
    "train_masks = np.load('train_masks.npy')\n",
    "test_images = np.load('test_images.npy')\n",
    "test_masks = np.load('test_masks.npy')\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = BrainTumorDataset(train_images, train_masks)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "test_dataset = BrainTumorDataset(test_images, test_masks)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Define model, optimizer, and loss function\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VNet(num_classes=4).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train = 0\n",
    "    train_dice = 0.0\n",
    "    train_hausdorff = 0.0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images = images.unsqueeze(1).to(device)  # Add channel dimension\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_correct += (predicted == masks).sum().item()\n",
    "        total_train += masks.numel()\n",
    "\n",
    "        for pred, mask in zip(predicted, masks):\n",
    "            train_dice += dice_coefficient(pred, mask)\n",
    "            train_hausdorff += hausdorff_distance(pred, mask)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_accuracy = train_correct / total_train\n",
    "    train_dice /= len(train_loader.dataset)\n",
    "    train_hausdorff /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    total_test = 0\n",
    "    test_dice = 0.0\n",
    "    test_hausdorff = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in test_loader:\n",
    "            images = images.unsqueeze(1).to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_correct += (predicted == masks).sum().item()\n",
    "            total_test += masks.numel()\n",
    "\n",
    "            for pred, mask in zip(predicted, masks):\n",
    "                test_dice += dice_coefficient(pred, mask)\n",
    "                test_hausdorff += hausdorff_distance(pred, mask)\n",
    "\n",
    "    test_accuracy = test_correct / total_test\n",
    "    test_dice /= len(test_loader.dataset)\n",
    "    test_hausdorff /= len(test_loader.dataset)\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, '\n",
    "          f'Train Dice: {train_dice:.4f}, Train Hausdorff: {train_hausdorff:.4f}, '\n",
    "          f'Test Accuracy: {test_accuracy:.4f}, Test Dice: {test_dice:.4f}, Test Hausdorff: {test_hausdorff:.4f}')\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'vnet_best_checkpoint.pth')\n",
    "        best_accuracy = test_accuracy\n",
    "\n",
    "print(f'Training complete. Best accuracy: {best_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6671e680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
