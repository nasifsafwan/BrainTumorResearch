{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1983313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from dataset import BrainTumorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084c79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a14c07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Skipping file /Users/nasifsafwan/Downloads/ML/BrainTumorResearch/tumordata/Training/glioma_tumor/.DS_Store as it is not a valid image.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = BrainTumorDataset(root_dir='/Users/nasifsafwan/Downloads/ML/BrainTumorResearch/tumordata/Training/',\n",
    "                                 transform=data_transforms['train'])\n",
    "val_dataset = BrainTumorDataset(root_dir='/Users/nasifsafwan/Downloads/ML/BrainTumorResearch/tumordata/Testing/'\n",
    "                                 ,transform=data_transforms['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62ea9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, models, num_classes):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.models = models\n",
    "        \n",
    "        # Get the feature sizes for each model\n",
    "        feature_sizes = []\n",
    "        for model in self.models:\n",
    "            feature_sizes.append(model.num_features)\n",
    "        \n",
    "        # Combined feature size\n",
    "        combined_feature_size = sum(feature_sizes)\n",
    "        \n",
    "        # Define the final fully connected layer\n",
    "        self.fc = nn.Linear(combined_feature_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for model in self.models:\n",
    "            outputs.append(model(x))\n",
    "        combined_output = torch.cat(outputs, dim=1)\n",
    "        x = self.fc(combined_output)\n",
    "        return x\n",
    "\n",
    "# Initialize models\n",
    "model1 = timm.create_model('resnet18', pretrained=True, num_classes=0)  # Output features only\n",
    "model2 = timm.create_model('efficientnet_b0', pretrained=True, num_classes=0)  # Output features only\n",
    "model3 = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=0)  # Output features only\n",
    "\n",
    "# Create the combined model\n",
    "num_classes = 4  # Adjust as necessary\n",
    "combined_model = CombinedModel([model1, model2, model3], num_classes=num_classes)\n",
    "\n",
    "# Print the model to verify\n",
    "print(combined_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b246bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "# Initialize loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(combined_model.parameters(), lr=1e-4)\n",
    "\n",
    "# Define the scheduler\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1661ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|█████████████████████████████████████████| 90/90 [25:43<00:00, 17.15s/it, loss=1.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|███████████████████████████████████████████████████| 13/13 [01:24<00:00,  6.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Accuracy: 0.4594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|███████████████████████████████████████| 90/90 [24:16<00:00, 16.18s/it, loss=0.779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Loss: 0.7824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|███████████████████████████████████████████████████| 13/13 [01:23<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Accuracy: 0.4898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|███████████████████████████████████████| 90/90 [23:39<00:00, 15.77s/it, loss=0.657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Loss: 0.6595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|███████████████████████████████████████████████████| 13/13 [01:23<00:00,  6.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Accuracy: 0.5152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|███████████████████████████████████████| 90/90 [23:33<00:00, 15.70s/it, loss=0.589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Loss: 0.5911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|███████████████████████████████████████████████████| 13/13 [01:23<00:00,  6.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Accuracy: 0.5254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|███████████████████████████████████████| 90/90 [25:40<00:00, 17.11s/it, loss=0.545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Loss: 0.5474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|███████████████████████████████████████████████████| 13/13 [01:24<00:00,  6.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Accuracy: 0.5508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|███████████████████████████████████████| 90/90 [24:54<00:00, 16.61s/it, loss=0.509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Loss: 0.5107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|███████████████████████████████████████████████████| 13/13 [01:24<00:00,  6.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Accuracy: 0.5482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20:  58%|██████████████████████▌                | 52/90 [15:06<10:21, 16.35s/it, loss=0.499]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    combined_model.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", ncols=100)\n",
    "    \n",
    "    for inputs, labels in train_bar:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = combined_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        train_bar.set_postfix(loss=running_loss / ((train_bar.n + 1) * train_loader.batch_size))\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    # Validation step\n",
    "    combined_model.eval()\n",
    "    running_corrects = 0\n",
    "    \n",
    "    val_bar = tqdm(val_loader, desc=\"Validation\", ncols=100)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_bar:\n",
    "            outputs = combined_model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    epoch_acc = running_corrects.double() / len(val_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Accuracy: {epoch_acc:.4f}')\n",
    "    \n",
    "    # Optional: Step the scheduler\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(combined_model.state_dict(), 'fine_tuned_combined_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2b0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
