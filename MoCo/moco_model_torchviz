digraph {
	graph [size="61.65,61.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	139341167822144 [label="
 (1, 128)" fillcolor=darkolivegreen1]
	139341412853184 [label=AddmmBackward0]
	139341412848720 -> 139341412853184
	139341175386128 [label="projection_head.2.bias
 (128)" fillcolor=lightblue]
	139341175386128 -> 139341412848720
	139341412848720 [label=AccumulateGrad]
	139341412847808 -> 139341412853184
	139341412847808 [label=ReluBackward0]
	139341412854144 -> 139341412847808
	139341412854144 [label=AddmmBackward0]
	139341412844448 -> 139341412854144
	139341166600864 [label="projection_head.0.bias
 (256)" fillcolor=lightblue]
	139341166600864 -> 139341412844448
	139341412844448 [label=AccumulateGrad]
	139341412859280 -> 139341412854144
	139341412859280 [label=ViewBackward0]
	139341412847136 -> 139341412859280
	139341412847136 [label=MeanBackward1]
	139341412850736 -> 139341412847136
	139341412850736 [label=ReluBackward0]
	139341412848096 -> 139341412850736
	139341412848096 [label=AddBackward0]
	139341412858800 -> 139341412848096
	139341412858800 [label=CudnnBatchNormBackward0]
	139341412847184 -> 139341412858800
	139341412847184 [label=ConvolutionBackward0]
	139341412857936 -> 139341412847184
	139341412857936 [label=ReluBackward0]
	139341412843776 -> 139341412857936
	139341412843776 [label=CudnnBatchNormBackward0]
	139341412855968 -> 139341412843776
	139341412855968 [label=ConvolutionBackward0]
	139341412843824 -> 139341412855968
	139341412843824 [label=ReluBackward0]
	139341412851840 -> 139341412843824
	139341412851840 [label=AddBackward0]
	139341412858992 -> 139341412851840
	139341412858992 [label=CudnnBatchNormBackward0]
	139341412855728 -> 139341412858992
	139341412855728 [label=ConvolutionBackward0]
	139341412851360 -> 139341412855728
	139341412851360 [label=ReluBackward0]
	139341412856016 -> 139341412851360
	139341412856016 [label=CudnnBatchNormBackward0]
	139341412859088 -> 139341412856016
	139341412859088 [label=ConvolutionBackward0]
	139341412858032 -> 139341412859088
	139341412858032 [label=ReluBackward0]
	139341412849728 -> 139341412858032
	139341412849728 [label=AddBackward0]
	139341412855296 -> 139341412849728
	139341412855296 [label=CudnnBatchNormBackward0]
	139341412856256 -> 139341412855296
	139341412856256 [label=ConvolutionBackward0]
	139341412854384 -> 139341412856256
	139341412854384 [label=ReluBackward0]
	139341412849152 -> 139341412854384
	139341412849152 [label=CudnnBatchNormBackward0]
	139341412857216 -> 139341412849152
	139341412857216 [label=ConvolutionBackward0]
	139341412850832 -> 139341412857216
	139341412850832 [label=ReluBackward0]
	139341412857072 -> 139341412850832
	139341412857072 [label=AddBackward0]
	139341412848288 -> 139341412857072
	139341412848288 [label=CudnnBatchNormBackward0]
	139341412847616 -> 139341412848288
	139341412847616 [label=ConvolutionBackward0]
	139341412847664 -> 139341412847616
	139341412847664 [label=ReluBackward0]
	139341412857408 -> 139341412847664
	139341412857408 [label=CudnnBatchNormBackward0]
	139341412855008 -> 139341412857408
	139341412855008 [label=ConvolutionBackward0]
	139341412855056 -> 139341412855008
	139341412855056 [label=ReluBackward0]
	139341412855536 -> 139341412855056
	139341412855536 [label=AddBackward0]
	139341412852944 -> 139341412855536
	139341412852944 [label=CudnnBatchNormBackward0]
	139341412858656 -> 139341412852944
	139341412858656 [label=ConvolutionBackward0]
	139341412859664 -> 139341412858656
	139341412859664 [label=ReluBackward0]
	139341412855104 -> 139341412859664
	139341412855104 [label=CudnnBatchNormBackward0]
	139341412847040 -> 139341412855104
	139341412847040 [label=ConvolutionBackward0]
	139341412844400 -> 139341412847040
	139341412844400 [label=ReluBackward0]
	139341412847712 -> 139341412844400
	139341412847712 [label=AddBackward0]
	139341412846992 -> 139341412847712
	139341412846992 [label=CudnnBatchNormBackward0]
	139341412858416 -> 139341412846992
	139341412858416 [label=ConvolutionBackward0]
	139341412855344 -> 139341412858416
	139341412855344 [label=ReluBackward0]
	139341412859328 -> 139341412855344
	139341412859328 [label=CudnnBatchNormBackward0]
	139341412855392 -> 139341412859328
	139341412855392 [label=ConvolutionBackward0]
	139341412852848 -> 139341412855392
	139341412852848 [label=ReluBackward0]
	139341412857552 -> 139341412852848
	139341412857552 [label=AddBackward0]
	139341412851312 -> 139341412857552
	139341412851312 [label=CudnnBatchNormBackward0]
	139341412847424 -> 139341412851312
	139341412847424 [label=ConvolutionBackward0]
	139341412852992 -> 139341412847424
	139341412852992 [label=ReluBackward0]
	139341412851216 -> 139341412852992
	139341412851216 [label=CudnnBatchNormBackward0]
	139341412851024 -> 139341412851216
	139341412851024 [label=ConvolutionBackward0]
	139341412849584 -> 139341412851024
	139341412849584 [label=ReluBackward0]
	139341412847472 -> 139341412849584
	139341412847472 [label=AddBackward0]
	139341412855440 -> 139341412847472
	139341412855440 [label=CudnnBatchNormBackward0]
	139341412843584 -> 139341412855440
	139341412843584 [label=ConvolutionBackward0]
	139341412848864 -> 139341412843584
	139341412848864 [label=ReluBackward0]
	139341412850880 -> 139341412848864
	139341412850880 [label=CudnnBatchNormBackward0]
	139341412852080 -> 139341412850880
	139341412852080 [label=ConvolutionBackward0]
	139341412848768 -> 139341412852080
	139341412848768 [label=MaxPool2DWithIndicesBackward0]
	139341412846656 -> 139341412848768
	139341412846656 [label=ReluBackward0]
	139341412854672 -> 139341412846656
	139341412854672 [label=CudnnBatchNormBackward0]
	139341412849824 -> 139341412854672
	139341412849824 [label=ConvolutionBackward0]
	139341412856592 -> 139341412849824
	139341186156240 [label="base_encoder.0.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	139341186156240 -> 139341412856592
	139341412856592 [label=AccumulateGrad]
	139341412851456 -> 139341412854672
	139341464827152 [label="base_encoder.1.weight
 (64)" fillcolor=lightblue]
	139341464827152 -> 139341412851456
	139341412851456 [label=AccumulateGrad]
	139341412857120 -> 139341412854672
	139341168929392 [label="base_encoder.1.bias
 (64)" fillcolor=lightblue]
	139341168929392 -> 139341412857120
	139341412857120 [label=AccumulateGrad]
	139341412845936 -> 139341412852080
	139341186168400 [label="base_encoder.4.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139341186168400 -> 139341412845936
	139341412845936 [label=AccumulateGrad]
	139341412847376 -> 139341412850880
	139341173912208 [label="base_encoder.4.0.bn1.weight
 (64)" fillcolor=lightblue]
	139341173912208 -> 139341412847376
	139341412847376 [label=AccumulateGrad]
	139341412843968 -> 139341412850880
	139341186159840 [label="base_encoder.4.0.bn1.bias
 (64)" fillcolor=lightblue]
	139341186159840 -> 139341412843968
	139341412843968 [label=AccumulateGrad]
	139341412857984 -> 139341412843584
	139341186160800 [label="base_encoder.4.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139341186160800 -> 139341412857984
	139341412857984 [label=AccumulateGrad]
	139341412851552 -> 139341412855440
	139341186161520 [label="base_encoder.4.0.bn2.weight
 (64)" fillcolor=lightblue]
	139341186161520 -> 139341412851552
	139341412851552 [label=AccumulateGrad]
	139341412859856 -> 139341412855440
	139341186167040 [label="base_encoder.4.0.bn2.bias
 (64)" fillcolor=lightblue]
	139341186167040 -> 139341412859856
	139341412859856 [label=AccumulateGrad]
	139341412848768 -> 139341412847472
	139341412851600 -> 139341412851024
	139341186170720 [label="base_encoder.4.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139341186170720 -> 139341412851600
	139341412851600 [label=AccumulateGrad]
	139341412858944 -> 139341412851216
	139341186170000 [label="base_encoder.4.1.bn1.weight
 (64)" fillcolor=lightblue]
	139341186170000 -> 139341412858944
	139341412858944 [label=AccumulateGrad]
	139341412851744 -> 139341412851216
	139341186160720 [label="base_encoder.4.1.bn1.bias
 (64)" fillcolor=lightblue]
	139341186160720 -> 139341412851744
	139341412851744 [label=AccumulateGrad]
	139341412845552 -> 139341412847424
	139341415820208 [label="base_encoder.4.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139341415820208 -> 139341412845552
	139341412845552 [label=AccumulateGrad]
	139341412848816 -> 139341412851312
	139341415819008 [label="base_encoder.4.1.bn2.weight
 (64)" fillcolor=lightblue]
	139341415819008 -> 139341412848816
	139341412848816 [label=AccumulateGrad]
	139341412853232 -> 139341412851312
	139341415814368 [label="base_encoder.4.1.bn2.bias
 (64)" fillcolor=lightblue]
	139341415814368 -> 139341412853232
	139341412853232 [label=AccumulateGrad]
	139341412849584 -> 139341412857552
	139341412852560 -> 139341412855392
	139341415816448 [label="base_encoder.5.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	139341415816448 -> 139341412852560
	139341412852560 [label=AccumulateGrad]
	139341412848432 -> 139341412859328
	139341415812288 [label="base_encoder.5.0.bn1.weight
 (128)" fillcolor=lightblue]
	139341415812288 -> 139341412848432
	139341412848432 [label=AccumulateGrad]
	139341412853568 -> 139341412859328
	139341415819968 [label="base_encoder.5.0.bn1.bias
 (128)" fillcolor=lightblue]
	139341415819968 -> 139341412853568
	139341412853568 [label=AccumulateGrad]
	139341412854768 -> 139341412858416
	139341415824048 [label="base_encoder.5.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	139341415824048 -> 139341412854768
	139341412854768 [label=AccumulateGrad]
	139341412847568 -> 139341412846992
	139341415820848 [label="base_encoder.5.0.bn2.weight
 (128)" fillcolor=lightblue]
	139341415820848 -> 139341412847568
	139341412847568 [label=AccumulateGrad]
	139341412846608 -> 139341412846992
	139341415818608 [label="base_encoder.5.0.bn2.bias
 (128)" fillcolor=lightblue]
	139341415818608 -> 139341412846608
	139341412846608 [label=AccumulateGrad]
	139341412845360 -> 139341412847712
	139341412845360 [label=CudnnBatchNormBackward0]
	139341412845840 -> 139341412845360
	139341412845840 [label=ConvolutionBackward0]
	139341412852848 -> 139341412845840
	139341412848000 -> 139341412845840
	139341415815568 [label="base_encoder.5.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	139341415815568 -> 139341412848000
	139341412848000 [label=AccumulateGrad]
	139341412853760 -> 139341412845360
	139341415812528 [label="base_encoder.5.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	139341415812528 -> 139341412853760
	139341412853760 [label=AccumulateGrad]
	139341412856928 -> 139341412845360
	139341415820288 [label="base_encoder.5.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	139341415820288 -> 139341412856928
	139341412856928 [label=AccumulateGrad]
	139341412854528 -> 139341412847040
	139341415819408 [label="base_encoder.5.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	139341415819408 -> 139341412854528
	139341412854528 [label=AccumulateGrad]
	139341412851504 -> 139341412855104
	139341415813008 [label="base_encoder.5.1.bn1.weight
 (128)" fillcolor=lightblue]
	139341415813008 -> 139341412851504
	139341412851504 [label=AccumulateGrad]
	139341412845456 -> 139341412855104
	139341415821168 [label="base_encoder.5.1.bn1.bias
 (128)" fillcolor=lightblue]
	139341415821168 -> 139341412845456
	139341412845456 [label=AccumulateGrad]
	139341412852704 -> 139341412858656
	139341415814848 [label="base_encoder.5.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	139341415814848 -> 139341412852704
	139341412852704 [label=AccumulateGrad]
	139341412847760 -> 139341412852944
	139341415819648 [label="base_encoder.5.1.bn2.weight
 (128)" fillcolor=lightblue]
	139341415819648 -> 139341412847760
	139341412847760 [label=AccumulateGrad]
	139341412853040 -> 139341412852944
	139341415815808 [label="base_encoder.5.1.bn2.bias
 (128)" fillcolor=lightblue]
	139341415815808 -> 139341412853040
	139341412853040 [label=AccumulateGrad]
	139341412844400 -> 139341412855536
	139341412845744 -> 139341412855008
	139341415823088 [label="base_encoder.6.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	139341415823088 -> 139341412845744
	139341412845744 [label=AccumulateGrad]
	139341412854432 -> 139341412857408
	139341415816288 [label="base_encoder.6.0.bn1.weight
 (256)" fillcolor=lightblue]
	139341415816288 -> 139341412854432
	139341412854432 [label=AccumulateGrad]
	139341412846848 -> 139341412857408
	139341415811008 [label="base_encoder.6.0.bn1.bias
 (256)" fillcolor=lightblue]
	139341415811008 -> 139341412846848
	139341412846848 [label=AccumulateGrad]
	139341412849920 -> 139341412847616
	139341415818208 [label="base_encoder.6.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139341415818208 -> 139341412849920
	139341412849920 [label=AccumulateGrad]
	139341412859376 -> 139341412848288
	139341415823248 [label="base_encoder.6.0.bn2.weight
 (256)" fillcolor=lightblue]
	139341415823248 -> 139341412859376
	139341412859376 [label=AccumulateGrad]
	139341412858560 -> 139341412848288
	139341415813168 [label="base_encoder.6.0.bn2.bias
 (256)" fillcolor=lightblue]
	139341415813168 -> 139341412858560
	139341412858560 [label=AccumulateGrad]
	139341412845216 -> 139341412857072
	139341412845216 [label=CudnnBatchNormBackward0]
	139341412845408 -> 139341412845216
	139341412845408 [label=ConvolutionBackward0]
	139341412855056 -> 139341412845408
	139341412858608 -> 139341412845408
	139341415810128 [label="base_encoder.6.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	139341415810128 -> 139341412858608
	139341412858608 [label=AccumulateGrad]
	139341412848048 -> 139341412845216
	139341415815088 [label="base_encoder.6.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	139341415815088 -> 139341412848048
	139341412848048 [label=AccumulateGrad]
	139341412844832 -> 139341412845216
	139341415815408 [label="base_encoder.6.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	139341415815408 -> 139341412844832
	139341412844832 [label=AccumulateGrad]
	139341412858224 -> 139341412857216
	139341415817488 [label="base_encoder.6.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139341415817488 -> 139341412858224
	139341412858224 [label=AccumulateGrad]
	139341412849056 -> 139341412849152
	139341415818288 [label="base_encoder.6.1.bn1.weight
 (256)" fillcolor=lightblue]
	139341415818288 -> 139341412849056
	139341412849056 [label=AccumulateGrad]
	139341412850928 -> 139341412849152
	139341415809568 [label="base_encoder.6.1.bn1.bias
 (256)" fillcolor=lightblue]
	139341415809568 -> 139341412850928
	139341412850928 [label=AccumulateGrad]
	139341412845984 -> 139341412856256
	139341415817168 [label="base_encoder.6.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	139341415817168 -> 139341412845984
	139341412845984 [label=AccumulateGrad]
	139341412859040 -> 139341412855296
	139341415814128 [label="base_encoder.6.1.bn2.weight
 (256)" fillcolor=lightblue]
	139341415814128 -> 139341412859040
	139341412859040 [label=AccumulateGrad]
	139341412846752 -> 139341412855296
	139341415819568 [label="base_encoder.6.1.bn2.bias
 (256)" fillcolor=lightblue]
	139341415819568 -> 139341412846752
	139341412846752 [label=AccumulateGrad]
	139341412850832 -> 139341412849728
	139341412855776 -> 139341412859088
	139341415824768 [label="base_encoder.7.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	139341415824768 -> 139341412855776
	139341412855776 [label=AccumulateGrad]
	139341412857888 -> 139341412856016
	139341415809808 [label="base_encoder.7.0.bn1.weight
 (512)" fillcolor=lightblue]
	139341415809808 -> 139341412857888
	139341412857888 [label=AccumulateGrad]
	139341412846512 -> 139341412856016
	139341415824928 [label="base_encoder.7.0.bn1.bias
 (512)" fillcolor=lightblue]
	139341415824928 -> 139341412846512
	139341412846512 [label=AccumulateGrad]
	139341412851168 -> 139341412855728
	139341415815488 [label="base_encoder.7.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139341415815488 -> 139341412851168
	139341412851168 [label=AccumulateGrad]
	139341412845312 -> 139341412858992
	139341415824448 [label="base_encoder.7.0.bn2.weight
 (512)" fillcolor=lightblue]
	139341415824448 -> 139341412845312
	139341412845312 [label=AccumulateGrad]
	139341412857504 -> 139341412858992
	139341415816688 [label="base_encoder.7.0.bn2.bias
 (512)" fillcolor=lightblue]
	139341415816688 -> 139341412857504
	139341412857504 [label=AccumulateGrad]
	139341412854192 -> 139341412851840
	139341412854192 [label=CudnnBatchNormBackward0]
	139341412850640 -> 139341412854192
	139341412850640 [label=ConvolutionBackward0]
	139341412858032 -> 139341412850640
	139341412846224 -> 139341412850640
	139341415817648 [label="base_encoder.7.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	139341415817648 -> 139341412846224
	139341412846224 [label=AccumulateGrad]
	139341412853472 -> 139341412854192
	139341415809728 [label="base_encoder.7.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	139341415809728 -> 139341412853472
	139341412853472 [label=AccumulateGrad]
	139341412846080 -> 139341412854192
	139341415825008 [label="base_encoder.7.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	139341415825008 -> 139341412846080
	139341412846080 [label=AccumulateGrad]
	139341412850784 -> 139341412855968
	139341415816848 [label="base_encoder.7.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139341415816848 -> 139341412850784
	139341412850784 [label=AccumulateGrad]
	139341412848144 -> 139341412843776
	139341415814528 [label="base_encoder.7.1.bn1.weight
 (512)" fillcolor=lightblue]
	139341415814528 -> 139341412848144
	139341412848144 [label=AccumulateGrad]
	139341412852368 -> 139341412843776
	139341415811488 [label="base_encoder.7.1.bn1.bias
 (512)" fillcolor=lightblue]
	139341415811488 -> 139341412852368
	139341412852368 [label=AccumulateGrad]
	139341412844256 -> 139341412847184
	139341415819328 [label="base_encoder.7.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	139341415819328 -> 139341412844256
	139341412844256 [label=AccumulateGrad]
	139341412848240 -> 139341412858800
	139341415810848 [label="base_encoder.7.1.bn2.weight
 (512)" fillcolor=lightblue]
	139341415810848 -> 139341412848240
	139341412848240 [label=AccumulateGrad]
	139341412846128 -> 139341412858800
	139341415814688 [label="base_encoder.7.1.bn2.bias
 (512)" fillcolor=lightblue]
	139341415814688 -> 139341412846128
	139341412846128 [label=AccumulateGrad]
	139341412843824 -> 139341412848096
	139341412843920 -> 139341412854144
	139341412843920 [label=TBackward0]
	139341412847952 -> 139341412843920
	139341443161744 [label="projection_head.0.weight
 (256, 512)" fillcolor=lightblue]
	139341443161744 -> 139341412847952
	139341412847952 [label=AccumulateGrad]
	139341412852608 -> 139341412853184
	139341412852608 [label=TBackward0]
	139341412854912 -> 139341412852608
	139341165728032 [label="projection_head.2.weight
 (128, 256)" fillcolor=lightblue]
	139341165728032 -> 139341412854912
	139341412854912 [label=AccumulateGrad]
	139341412853184 -> 139341167822144
}
